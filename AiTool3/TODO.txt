
TODO:

DONE: crashes if a find and replace won't apply 
DONE: Token counting
DONE: Support bitmaps (OpenAI and Claude)
DONE: Support system prompts
DONE: Support categories
DONE: Amend ButtonedRichTextBox with a param, if true, flash when content updated
DONE: Make passwords configurable
DONE: pass thru stringselected insatead of using event per layer
DONE: Streaming
DONE: Add dummy root message to conversations, to join root user messages together
DONE: add clear-search button
DONE: add multiple files attach button
DONE: add "continue..." funcitionality that concats messages, prob don't need to keep sensible history of this
DONE: JSON array viewer might be nice
DONE: It probably sucks when the AI is running and the user changes conversations
DONE: Do more to not mess up the conversation if user changes nodes while the AI is running
DONE: Licenses 
DONE: Inline JS for appropriate packages : D3 v7, cytoscape, jsoneditor
DONE: discard edit-highlighting-colours functionality
DONE: Make default engine sticky
DONE: add template category
DONE: Transcribe MP4, WAV, ...
DONE: fix the double-press-of-Send bug
DONE: Allow choice of summary engine
DONE: Embeddings - make sure they're not being used for summaries
DONE(ish): Embeddings - provide drop-down to choose embedding from a specific directory
DONE: llava support
DONE: Add template category
DONE: send embeddings wrong colour after clicking node in ndc
DONE: File drag-and-drop
DONE: Handle if there's no local AI (is this an issue at all? if port is closed, it just doesn't work)
DONE: drag and drop urls to main part of window
DONE: highlight the currently-selected template in the templates menu
DONE: Delete template
DONE: "NONE" option at the top of the templates menu
DONE: add big yellow use-embeddings button? Add text "WITH EMBEDDINGS" to send button and make it yellow?
DONE: delete template
DONE: if there's no local AI at all, deal with it
DONE: It'd be lovely if you could highlight a conversation with one of four nice pastel colours, to mark one for later reference
DONE: Rename to MaxsAiStudio
DONE: tiny bug: fullscreen user prompt button is a Bit Crap
DONE: Ongoing token counting
DONE: Make convo browser visible sticky
DONE: bug: new-with-context doesn't work properly
DONE: Delete-conversation (for failed conversations innit)
DONE: bug: api key setting doesn't seem to stick
DONE: bug: chat input is too big in full-screen
DONE: 4/5: fix images aren't included in Groq history
DONE: PlantUML viewer
DONE (as it can be): Streaming token counting is done for Claude
DONE: Make use of token counting
DONE: fix scroll to bottom when adding streaming fragment
DONE: Hide project browser behind experimental setting? At least needs tidying up
DONE: Image from clipboard
DONE: cr's in template names cause menu nastiness
DONE: On first run, create subdirs: Conversations, Settings, Templates, Embeddings
DONE: json mode / tools ?
DONE: Add spinner while embeddings are generated
DONE: add a "continue" button at the end of an unterminated code block.  When clicked, fetch the next response and auto-concat.
DONE: fix // bit thin, this...
DONE: Persistent themes
DONE: move conversations to subdirectory, templates to another, settings to a third?
DONE: basic scratchpad
DONE: Seems like Cancel button doesn't work
DONE: Add the ability to Delete Theme
DONE: SVG? we already have svg-pan-zoom
DONE: allow setting of proper URLs for local AI
DONE: Cublas and non-Cublas builds for whisperx (file transcription) - need dlls from another source - whisperX?DONE: allow setting of proper URLs for local AI
DONE: Theme names shouldn't be specified by property names, but by properties
DONE: Tools should be specified by extrenal files and mapped in
DONE: Possihble nasty bug in deleting themes
DONE: Shouldn't be an "add" on the categories page unless it works...
DONE:add delete-template
DONE: popup that lets you pick embedding results to submit?
DONE: Concatenate messages
DONE: It'd be nice if you could outright edit responses in the conversation - should really be able to do this
DONE: Ollama Tool Support via OpenAI
DONE: Fix incomplete tools menu - add theme-generation tool
DONE: regen all summaries
DONE: Check whisper still works through microphone
DONE: js => jsx
SORT-OF-DONE (can edit raw) : Copy response as raw text (no backtick issues!)
DONE: fix the load-thousands-of-conversations bug
DONE: selected theme isn't sticking  when installing theme directly
DONE? : Cancel button didn't work during Claude streaming response
DONE: scroll to bottom when appending temp-ai/user-msg otherwise scroll to top
DONE: if there's no Settings file, open settings on first run
DONE: ask for API/local AI details
DONE: inline https://unpkg.com/viz.js@2.1.2/viz.js
DONE: Improve recording button toggle whatnot
DONE: Loading spinner while working out the project helper
DONE: That weird one where you've picked a conersation but not a mesasge, and try to send a new message.  I suppose when you click a conversation, it could jump to the most recent message.
DONE: Ensure "Continue" button doesn't appear on temp-ai-msg
DONE: Add "go to top" button at bottom of message
DONE: CTRL-SHIFT-RETURn to send to alternate AI
DONE: Timer keeps running on cancel?
DONE (sort of): project helper: for fixed or new files, write to project structure? (!) - could use tool for this?
DONE: popup that lets you interfere with the embeddings selected...!
DONE: source code browser thing, to let you choose which files to upload from your project?
DONE: Github version check
DONE: Add "working" to transcribe
DONE (sort-of): Allow choice of embedding engine?
DONE: Remove unnecessary experiments
DONE: Add another handler like formattedcontent for urls
DONE: Parameterise conda loading
DONE: example templates set incl colour scheme generator
DONE: Change "first local engine" logic and null summary model
DONE: Template tool, to help AI generate new templates which we then install easily
DONE: covn manager doesn't unlock when chat returns?
DONE: better model selection generally

VSIXDONE: all open files
VSIXDONE: make the inter-process comms much more stable
VSIXDONE (sort of): add proper completion support for autocomplete, which will require the use of a tool

""serene"" bug

VSIX:

 Make full web UI visible in VS:
  DONE: move resources to shared dll
  DONE: path app to fetch resources from dll

  When a VSXIUI message is received by VSIX, pass it via TCP to the app and process it as if it was a message from the main webview

  When the main app sends a message to the main web view, also send it via TCP to the app.
    - 
  
  rebuild all the vs functionality from MessagePrompts

  

 plugin status should be visible from within VSTS and the app
  
 autocomplete should probably be hard-wired to the summary engine

 - not using system prompts at this stage :/

 - copy button is buggy, others don't work at all :/

 - flipping tabs in vs causes it to reset somehow
  
 - right-click menu options? on pop-on-select?

 - all files in solution?
 - all files in project?

 - could define filegroups and then reference those, a bit like a much-better project helper

* There's a bug when installing a new theme (and it shouldn't crash the whole app :) if it has no id? I think?
* rename arrayfindandreplace
* should be able to tell which LLMs/APIs support tools
* check which provider classes implement temperature correctly :/
File explorer needs a clear-all button and possibly a next-search-result button

For VS typew work, you might have a very long system prompt that's cached, telling it what's what.

* some kind of clean-build test might be nice...

Would be nice if you could collapse code blocks in both the editors and the messages

Tips thing in status bar woudl be excellent, especially if it could link to supporting information
Clean build : check whisper can be got up-and-running and doesn't b0rk too badly beforehand
Claude pre-fills
OPenAI structured output

Does the damned thing work offline or is there still a dependency that prevents that?

Implement streaming part of claude prompt caching


-=-

Versionize settings and preserve old settings/themes/templates etc on new version?

-=-

Claude prompt caching
 - token handling
 DONE: requires datetime fix
 - turn off and on - cog next to AI model?
   - cache first message versus don't cache first message versus don't use the cacheing beta
 - needs 1024-token minimum...! :/
 - visual indicator that a message has been cached
 - just the first user message, or ... ?

 Add flag to model, SupportsPromptCaching.  

 COuld have another thing on the send button, "Send and cache to the end of this prompt" or similar - but only models where SupportsPromptCaching.  

 We can use the caching beta all the time if supportspromptcaching i guess, because if you don't ask for anything to be cached, nothign changes.

 Allow a covnersation message to be marked as cached with its date and time. This needs to be updated whenever we confirm we've just used the cache.

 need to extend tokenusage so it can cope with the new kinds of token and their pricing

 but really you want to cache the systemprompt and first userprompt but add more to it...

 Or, could cache all the code dumped across by the project helper, but not the rest of the prompt - IF we reworked how the project helper passes its files in

 Or, you could insert some sort of "Cache to here" marker in your prompt?

 Maybe an "auto-cache the first message if possible" metaphor is good?

 We could capture the "not enough input" error and run rerun without caching... :/

 But surely the likelihood is that if you're dumping a huge amount into one window, you're going to want to ask many follow-up questions?

 It just doesn't help so much when you get the initial question wrong!

 Maybe a marker in the input box which says "cache to here" which you can drag or move with the right mouse button? :/

 Or you could "Send and cache all", or "Send and cache to...".  The latter works out the conversation and lets you set a point somewhere in it, to cache to.  We insert a marker or track the location against the 
 message so that we can build the correct cached part separately from the rest.

 Say the first message you sent is cached (and ofc we know that).

 You click on the first message and amend it.  If you only add to it, we can reuse the cache as long as we detect that.  Or maybe (better) when you click on the cached object, it DOESN'T LET you
 change the cached part without some interaction first ("editing this will invalidate your cached data").  But you probably do want to amend the cached bit, because the whole first message is cached.

 Would be nice if it could tell you how much you'd saved using it!

 How about we implement a bucnh of different strategies (cache nothing, cache system prompt, cache to end of first input, cache to end of files in first input, cache to end of current user message,
 cache to "MARKERLOL", ...)
  on a "settings" bar for the (main?) AI, which can be left visible to easily pick a strategy, and which is sticky between sessions.

  With cachesystemprompt... do we need to hold it in memory for 5 minutes so we can tell it's still cached when you satrt a new conversation?!

  Maybe don't need to go there if we have "cache to "MARKERLOL"".

  
  !
     - Add a "Cache to here" marker at the left side of the current user chat message, which can be dragged up and down!
     Or provide "cache to here" buttons and some kind of vertical green line type marker to indicate what's currently marked to be cached...?

     You would think that if you marked up the first bit, sthen marked up another bit, the first bit  would be used to cheaply build the second bit... :/
     CONFIRMED and this is why you might (say) mark the last four user messages!

     Caching is use-or-create...

     Claude estimates 28% reply from user to AI freq before caching is cheaper, but this ignores that earlier messagres are typically longer.  the last messages, where caching was "wasted", are typically.

     Running pair means you're always rebuilding the cache up-to-date and maximising the savings

     You can cache the last four message points, so you could highlight those as being available?  But something doesn't need to have been cached by the last req to be cached...

     Maybe this does mean we need a memory log of what's been cached with expiry, so we can tell how to reuse?

     Could we do that? 

     Prompt Caching references the entire prompt - tools, system, and messages up to and including the block designated with cache_control.


 -=-

externalise tool definitions

~~~~~~~~~~ Further ideas


project helper: # to include files?
add more theme settings?
launch sql? browse xml? launch svg? azure az command?! 
launch JS directly would be nice
Choose-microphone

enable/disable cs/html highlighting
Pick-a-frame-from-a-video

*  syntax highlighting in messages

support markdown? :/
regex viewer? :/
css viewer?

Fade out and back in instead of smooth scrolling?
Templaets should be able to specify tools they're used wsith => colour scheme tool!
add time-taken to search results and timestamp to all convo messages
alter to proper attachments model w multiple images, files saved in original form, etc?

Tip of the day
add tokens-per-second to the status bar?
Different Whisper models w/ UI
templates edit window is pretty crappy

Create embeddings from previous messages/conversations?
Custom handlers? External links to other apps or handlers?
AI ideas:
• Ability to export conversations in various formats (PDF, DOCX, etc.)
• Ability to import conversations in various formats (PDF, DOCX, etc.)
• Collaborative real-time editing for shared conversations lol
• Sentiment analysis for conversation messages lol




~~~ Tools

an ai tool, in this context, is one an AI can use to request that an action be carried out, outside its domain, to help complete its assigned task. Completely rewrite your list
AI
I apologize for the misunderstanding. Thank you for clarifying. Here's a revised list of 20 AI tools that an AI could request to use for completing tasks outside its domain:

1. Web scraper: to gather information from websites
2. Database query executor: to retrieve specific data from databases
3. File system navigator: to search and access files on a system
4. API caller: to interact with external services and fetch data
5. Email sender: to compose and send emails
6. Calendar scheduler: to create, modify, or delete calendar events
7. Document converter: to change file formats (e.g., PDF to Word)
8. Image editor: to manipulate images (resize, crop, filter)
9. Video processor: to edit or analyze video content
10. Audio manipulator: to edit or analyze audio files
11. Geolocation service: to get or interpret geographic data
12. Weather data fetcher: to retrieve current or forecasted weather information
13. Currency converter: to perform real-time currency conversions
14. Social media poster: to publish content on various social platforms
15. SMS sender: to send text messages to phone numbers
16. Data visualizer: to create charts or graphs from datasets
17. QR code generator: to create QR codes from given information
18. URL shortener: to create shortened versions of long URLs
19. Encryption/decryption tool: to secure or access protected information
20. System resource monitor: to check CPU, memory, or disk usage








1. Multiple AI Model Support
   - Support for various AI models (e.g., GPT-4, GPT-3.5-turbo, Claude, Gemini, local models)
   - Ability to switch between different AI models for main conversation and summaries

2. Conversation Management
   - Save and load conversations
   - Organize conversations with summaries and highlights
   - Search through past conversations
   - Edit raw message content
   - Continue unfinished code blocks or responses
   - Branched conversations

3. Templates System
   - Create, edit, and manage conversation templates
   - Organize templates into categories
   - Quick access to templates for starting new conversations

4. File Attachment and Processing
   - Attach images to conversations
   - Transcribe audio and video files using Whisper
   - Drag and drop file support
   - Process and embed content from various file types (e.g., CS, HTML, XML, JSON, JS)

5. Code Handling
   - Syntax highlighting for various programming languages
   - Code block actions (copy, save, execute)
   - Find and replace tool (tools work in Claude, OpenAI and Ollama only)

6. Embeddings and Context
   - Generate and use embeddings for enhanced context
   - Select or reject code snippets identified via embeddings

7. Voice Input and Output
   - Voice recording for input
   - Text-to-speech for AI responses

8. Visualization Tools
   - Network diagram for conversation flow
   - Mermaid diagram support
   - PlantUML diagram support
   - DOT graph visualization

9. Project Helper
   - Browse and select project files from a fixed root directory (configured in Settings)
   - Gitignore-aware file filtering

10. Theme Customization
    - Create and edit custom color schemes using a specific tool (tools work in Claude, OpenAI and Ollama only)
    - Apply themes to the user interface

11. Special Features
    - Auto-suggest for conversation continuations
    - Generate and update README files
    - Code review functionality
    - Transcribe MP4 files

12. Usage Statistics
    - Track token usage and costs for different models
    - View and reset usage statistics

13. Web Interface
    - Built-in web server for remote access (experimental feature)

14. Utility Functions
    - Scratchpad for quick notes, editing etc.
    - Execute Python and PowerShell scripts
    - Launch STL files
    - JSON viewer and editor

15. Customization Options
    - Adjust AI parameters (e.g., temperature)
    - Configure file extensions for project helper
    - Set default paths and embedding files

16. Interface Features
    - Collapsible conversation pane

17. Export Options
    - Save conversations as TXT or HTML
   

